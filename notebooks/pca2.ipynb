{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICR - Identifying Age-Related Conditions¶\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Machine Learning to detect conditions with measurements of anonymous characteristics\n",
    "https://www.kaggle.com/code/samuelabatnehendalie/icr-identifying-age-related-conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' use this code when upload to kaggle\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\\n# For example, here\\'s several helpful packages to load\\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Input data files are available in the read-only \"../input/\" directory\\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\\n\\nimport os\\nfor dirname, _, filenames in os.walk(\\'/kaggle/input\\'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\\n# You can also write temporary files to /kaggle/temp/, but they won\\'t be saved outside of the current session\\n\\n\\ntrain = pd.read_csv(\\'/kaggle/input/icr-identify-age-related-conditions/train.csv\\')\\ntest = pd.read_csv(\\'/kaggle/input/icr-identify-age-related-conditions/test.csv\\')\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' use this code when upload to kaggle\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(directory, \"train.csv\"))\n",
    "meta_data = pd.read_csv(os.path.join(directory, \"greeks.csv\"))\n",
    "test = pd.read_csv(os.path.join(directory, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>...</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ff2bfdfe9</td>\n",
       "      <td>0.209377</td>\n",
       "      <td>3109.03329</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>22.394407</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>0.699861</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>9.812214</td>\n",
       "      <td>5.555634</td>\n",
       "      <td>...</td>\n",
       "      <td>7.298162</td>\n",
       "      <td>1.73855</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>11.339138</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2003.810319</td>\n",
       "      <td>22.136229</td>\n",
       "      <td>69.834944</td>\n",
       "      <td>0.120343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007255e47698</td>\n",
       "      <td>0.145282</td>\n",
       "      <td>978.76416</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>36.968889</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.632190</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>13.517790</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.568932</td>\n",
       "      <td>9.292698</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>27981.562750</td>\n",
       "      <td>29.135430</td>\n",
       "      <td>32.131996</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>013f2bd269f5</td>\n",
       "      <td>0.470030</td>\n",
       "      <td>2635.10654</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>32.360553</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.732840</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>12.824570</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>...</td>\n",
       "      <td>7.709560</td>\n",
       "      <td>0.97556</td>\n",
       "      <td>1.198821</td>\n",
       "      <td>37.077772</td>\n",
       "      <td>88.609437</td>\n",
       "      <td>13676.957810</td>\n",
       "      <td>28.022851</td>\n",
       "      <td>35.192676</td>\n",
       "      <td>0.196941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>043ac50845d5</td>\n",
       "      <td>0.252107</td>\n",
       "      <td>3819.65177</td>\n",
       "      <td>120.201618</td>\n",
       "      <td>77.112203</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.685344</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>11.053708</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.122162</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>18.529584</td>\n",
       "      <td>82.416803</td>\n",
       "      <td>2094.262452</td>\n",
       "      <td>39.948656</td>\n",
       "      <td>90.493248</td>\n",
       "      <td>0.155829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>044fb8a146ec</td>\n",
       "      <td>0.380297</td>\n",
       "      <td>3733.04844</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>14.103738</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.942255</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>102.151980</td>\n",
       "      <td>...</td>\n",
       "      <td>8.153058</td>\n",
       "      <td>48.50134</td>\n",
       "      <td>0.121914</td>\n",
       "      <td>16.408728</td>\n",
       "      <td>146.109943</td>\n",
       "      <td>8524.370502</td>\n",
       "      <td>45.381316</td>\n",
       "      <td>36.262628</td>\n",
       "      <td>0.096614</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id        AB          AF          AH         AM        AR  \\\n",
       "0  000ff2bfdfe9  0.209377  3109.03329   85.200147  22.394407  8.138688   \n",
       "1  007255e47698  0.145282   978.76416   85.200147  36.968889  8.138688   \n",
       "2  013f2bd269f5  0.470030  2635.10654   85.200147  32.360553  8.138688   \n",
       "3  043ac50845d5  0.252107  3819.65177  120.201618  77.112203  8.138688   \n",
       "4  044fb8a146ec  0.380297  3733.04844   85.200147  14.103738  8.138688   \n",
       "\n",
       "         AX        AY         AZ          BC  ...        FL        FR  \\\n",
       "0  0.699861  0.025578   9.812214    5.555634  ...  7.298162   1.73855   \n",
       "1  3.632190  0.025578  13.517790    1.229900  ...  0.173229   0.49706   \n",
       "2  6.732840  0.025578  12.824570    1.229900  ...  7.709560   0.97556   \n",
       "3  3.685344  0.025578  11.053708    1.229900  ...  6.122162   0.49706   \n",
       "4  3.942255  0.054810   3.396778  102.151980  ...  8.153058  48.50134   \n",
       "\n",
       "         FS         GB          GE            GF         GH         GI  \\\n",
       "0  0.094822  11.339138   72.611063   2003.810319  22.136229  69.834944   \n",
       "1  0.568932   9.292698   72.611063  27981.562750  29.135430  32.131996   \n",
       "2  1.198821  37.077772   88.609437  13676.957810  28.022851  35.192676   \n",
       "3  0.284466  18.529584   82.416803   2094.262452  39.948656  90.493248   \n",
       "4  0.121914  16.408728  146.109943   8524.370502  45.381316  36.262628   \n",
       "\n",
       "          GL  Class  \n",
       "0   0.120343      1  \n",
       "1  21.978000      0  \n",
       "2   0.196941      0  \n",
       "3   0.155829      0  \n",
       "4   0.096614      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head() # a lot of columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>...</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>617.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.477149</td>\n",
       "      <td>3502.013221</td>\n",
       "      <td>118.624513</td>\n",
       "      <td>38.968552</td>\n",
       "      <td>10.128242</td>\n",
       "      <td>5.545576</td>\n",
       "      <td>0.060320</td>\n",
       "      <td>10.566447</td>\n",
       "      <td>8.053012</td>\n",
       "      <td>5350.388655</td>\n",
       "      <td>...</td>\n",
       "      <td>5.433199</td>\n",
       "      <td>3.533905</td>\n",
       "      <td>0.421501</td>\n",
       "      <td>20.724856</td>\n",
       "      <td>131.714987</td>\n",
       "      <td>14679.595398</td>\n",
       "      <td>31.489716</td>\n",
       "      <td>50.584437</td>\n",
       "      <td>8.530961</td>\n",
       "      <td>0.175041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.468388</td>\n",
       "      <td>2300.322717</td>\n",
       "      <td>127.838950</td>\n",
       "      <td>69.728226</td>\n",
       "      <td>10.518877</td>\n",
       "      <td>2.551696</td>\n",
       "      <td>0.416817</td>\n",
       "      <td>4.350645</td>\n",
       "      <td>65.166943</td>\n",
       "      <td>3021.326641</td>\n",
       "      <td>...</td>\n",
       "      <td>11.496257</td>\n",
       "      <td>50.181948</td>\n",
       "      <td>1.305365</td>\n",
       "      <td>9.991907</td>\n",
       "      <td>144.181524</td>\n",
       "      <td>19352.959387</td>\n",
       "      <td>9.864239</td>\n",
       "      <td>36.266251</td>\n",
       "      <td>10.327010</td>\n",
       "      <td>0.380310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.081187</td>\n",
       "      <td>192.593280</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>3.177522</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>0.699861</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>1693.624320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.497060</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>4.102182</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>13.038894</td>\n",
       "      <td>9.432735</td>\n",
       "      <td>0.897628</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.252107</td>\n",
       "      <td>2197.345480</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>12.270314</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>4.128294</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>8.129580</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4155.702870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.497060</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>14.036718</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2798.992584</td>\n",
       "      <td>25.034888</td>\n",
       "      <td>23.011684</td>\n",
       "      <td>0.124392</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.354659</td>\n",
       "      <td>3120.318960</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>20.533110</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>5.031912</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>10.461320</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4997.960730</td>\n",
       "      <td>...</td>\n",
       "      <td>3.028141</td>\n",
       "      <td>1.131000</td>\n",
       "      <td>0.250601</td>\n",
       "      <td>18.771436</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>7838.273610</td>\n",
       "      <td>30.608946</td>\n",
       "      <td>41.007968</td>\n",
       "      <td>0.337827</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.559763</td>\n",
       "      <td>4361.637390</td>\n",
       "      <td>113.739540</td>\n",
       "      <td>39.139886</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.431634</td>\n",
       "      <td>0.036845</td>\n",
       "      <td>12.969516</td>\n",
       "      <td>5.081244</td>\n",
       "      <td>6035.885700</td>\n",
       "      <td>...</td>\n",
       "      <td>6.238814</td>\n",
       "      <td>1.512060</td>\n",
       "      <td>0.535067</td>\n",
       "      <td>25.608406</td>\n",
       "      <td>127.591671</td>\n",
       "      <td>19035.709240</td>\n",
       "      <td>36.863947</td>\n",
       "      <td>67.931664</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.161666</td>\n",
       "      <td>28688.187660</td>\n",
       "      <td>1910.123198</td>\n",
       "      <td>630.518230</td>\n",
       "      <td>178.943634</td>\n",
       "      <td>38.270880</td>\n",
       "      <td>10.315851</td>\n",
       "      <td>38.971568</td>\n",
       "      <td>1463.693448</td>\n",
       "      <td>53060.599240</td>\n",
       "      <td>...</td>\n",
       "      <td>137.932739</td>\n",
       "      <td>1244.227020</td>\n",
       "      <td>31.365763</td>\n",
       "      <td>135.781294</td>\n",
       "      <td>1497.351958</td>\n",
       "      <td>143790.071200</td>\n",
       "      <td>81.210825</td>\n",
       "      <td>191.194764</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               AB            AF           AH          AM          AR  \\\n",
       "count  617.000000    617.000000   617.000000  617.000000  617.000000   \n",
       "mean     0.477149   3502.013221   118.624513   38.968552   10.128242   \n",
       "std      0.468388   2300.322717   127.838950   69.728226   10.518877   \n",
       "min      0.081187    192.593280    85.200147    3.177522    8.138688   \n",
       "25%      0.252107   2197.345480    85.200147   12.270314    8.138688   \n",
       "50%      0.354659   3120.318960    85.200147   20.533110    8.138688   \n",
       "75%      0.559763   4361.637390   113.739540   39.139886    8.138688   \n",
       "max      6.161666  28688.187660  1910.123198  630.518230  178.943634   \n",
       "\n",
       "               AX          AY          AZ           BC           BD   ...  \\\n",
       "count  617.000000  617.000000  617.000000   617.000000    617.000000  ...   \n",
       "mean     5.545576    0.060320   10.566447     8.053012   5350.388655  ...   \n",
       "std      2.551696    0.416817    4.350645    65.166943   3021.326641  ...   \n",
       "min      0.699861    0.025578    3.396778     1.229900   1693.624320  ...   \n",
       "25%      4.128294    0.025578    8.129580     1.229900   4155.702870  ...   \n",
       "50%      5.031912    0.025578   10.461320     1.229900   4997.960730  ...   \n",
       "75%      6.431634    0.036845   12.969516     5.081244   6035.885700  ...   \n",
       "max     38.270880   10.315851   38.971568  1463.693448  53060.599240  ...   \n",
       "\n",
       "               FL           FR          FS          GB           GE  \\\n",
       "count  616.000000   617.000000  615.000000  617.000000   617.000000   \n",
       "mean     5.433199     3.533905    0.421501   20.724856   131.714987   \n",
       "std     11.496257    50.181948    1.305365    9.991907   144.181524   \n",
       "min      0.173229     0.497060    0.067730    4.102182    72.611063   \n",
       "25%      0.173229     0.497060    0.067730   14.036718    72.611063   \n",
       "50%      3.028141     1.131000    0.250601   18.771436    72.611063   \n",
       "75%      6.238814     1.512060    0.535067   25.608406   127.591671   \n",
       "max    137.932739  1244.227020   31.365763  135.781294  1497.351958   \n",
       "\n",
       "                  GF          GH          GI          GL       Class  \n",
       "count     617.000000  617.000000  617.000000  616.000000  617.000000  \n",
       "mean    14679.595398   31.489716   50.584437    8.530961    0.175041  \n",
       "std     19352.959387    9.864239   36.266251   10.327010    0.380310  \n",
       "min        13.038894    9.432735    0.897628    0.001129    0.000000  \n",
       "25%      2798.992584   25.034888   23.011684    0.124392    0.000000  \n",
       "50%      7838.273610   30.608946   41.007968    0.337827    0.000000  \n",
       "75%     19035.709240   36.863947   67.931664   21.978000    0.000000  \n",
       "max    143790.071200   81.210825  191.194764   21.978000    1.000000  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe() # may be coming from different distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 617 entries, 0 to 616\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Id      617 non-null    object \n",
      " 1   AB      617 non-null    float64\n",
      " 2   AF      617 non-null    float64\n",
      " 3   AH      617 non-null    float64\n",
      " 4   AM      617 non-null    float64\n",
      " 5   AR      617 non-null    float64\n",
      " 6   AX      617 non-null    float64\n",
      " 7   AY      617 non-null    float64\n",
      " 8   AZ      617 non-null    float64\n",
      " 9   BC      617 non-null    float64\n",
      " 10  BD      617 non-null    float64\n",
      " 11  BN      617 non-null    float64\n",
      " 12  BP      617 non-null    float64\n",
      " 13  BQ      557 non-null    float64\n",
      " 14  BR      617 non-null    float64\n",
      " 15  BZ      617 non-null    float64\n",
      " 16  CB      615 non-null    float64\n",
      " 17  CC      614 non-null    float64\n",
      " 18  CD      617 non-null    float64\n",
      " 19  CF      617 non-null    float64\n",
      " 20  CH      617 non-null    float64\n",
      " 21  CL      617 non-null    float64\n",
      " 22  CR      617 non-null    float64\n",
      " 23  CS      617 non-null    float64\n",
      " 24  CU      617 non-null    float64\n",
      " 25  CW      617 non-null    float64\n",
      " 26  DA      617 non-null    float64\n",
      " 27  DE      617 non-null    float64\n",
      " 28  DF      617 non-null    float64\n",
      " 29  DH      617 non-null    float64\n",
      " 30  DI      617 non-null    float64\n",
      " 31  DL      617 non-null    float64\n",
      " 32  DN      617 non-null    float64\n",
      " 33  DU      616 non-null    float64\n",
      " 34  DV      617 non-null    float64\n",
      " 35  DY      617 non-null    float64\n",
      " 36  EB      617 non-null    float64\n",
      " 37  EE      617 non-null    float64\n",
      " 38  EG      617 non-null    float64\n",
      " 39  EH      617 non-null    float64\n",
      " 40  EJ      617 non-null    object \n",
      " 41  EL      557 non-null    float64\n",
      " 42  EP      617 non-null    float64\n",
      " 43  EU      617 non-null    float64\n",
      " 44  FC      616 non-null    float64\n",
      " 45  FD      617 non-null    float64\n",
      " 46  FE      617 non-null    float64\n",
      " 47  FI      617 non-null    float64\n",
      " 48  FL      616 non-null    float64\n",
      " 49  FR      617 non-null    float64\n",
      " 50  FS      615 non-null    float64\n",
      " 51  GB      617 non-null    float64\n",
      " 52  GE      617 non-null    float64\n",
      " 53  GF      617 non-null    float64\n",
      " 54  GH      617 non-null    float64\n",
      " 55  GI      617 non-null    float64\n",
      " 56  GL      616 non-null    float64\n",
      " 57  Class   617 non-null    int64  \n",
      "dtypes: float64(55), int64(1), object(2)\n",
      "memory usage: 279.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info() # can see that there are several null values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BQ    60\n",
      "CB     2\n",
      "CC     3\n",
      "DU     1\n",
      "EL    60\n",
      "FC     1\n",
      "FL     1\n",
      "FS     2\n",
      "GL     1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_cols = train.columns[train.isnull().any()]\n",
    "print(train[null_cols].isnull().sum()) # remove BQ and EL since they have more 50 null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.drop(['BQ', 'EL'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "null_cols = train.columns[train.isnull().any()]\n",
    "for col in null_cols:\n",
    "    train[col].fillna(train[col].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 617 entries, 0 to 616\n",
      "Data columns (total 56 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Id      617 non-null    object \n",
      " 1   AB      617 non-null    float64\n",
      " 2   AF      617 non-null    float64\n",
      " 3   AH      617 non-null    float64\n",
      " 4   AM      617 non-null    float64\n",
      " 5   AR      617 non-null    float64\n",
      " 6   AX      617 non-null    float64\n",
      " 7   AY      617 non-null    float64\n",
      " 8   AZ      617 non-null    float64\n",
      " 9   BC      617 non-null    float64\n",
      " 10  BD      617 non-null    float64\n",
      " 11  BN      617 non-null    float64\n",
      " 12  BP      617 non-null    float64\n",
      " 13  BR      617 non-null    float64\n",
      " 14  BZ      617 non-null    float64\n",
      " 15  CB      617 non-null    float64\n",
      " 16  CC      617 non-null    float64\n",
      " 17  CD      617 non-null    float64\n",
      " 18  CF      617 non-null    float64\n",
      " 19  CH      617 non-null    float64\n",
      " 20  CL      617 non-null    float64\n",
      " 21  CR      617 non-null    float64\n",
      " 22  CS      617 non-null    float64\n",
      " 23  CU      617 non-null    float64\n",
      " 24  CW      617 non-null    float64\n",
      " 25  DA      617 non-null    float64\n",
      " 26  DE      617 non-null    float64\n",
      " 27  DF      617 non-null    float64\n",
      " 28  DH      617 non-null    float64\n",
      " 29  DI      617 non-null    float64\n",
      " 30  DL      617 non-null    float64\n",
      " 31  DN      617 non-null    float64\n",
      " 32  DU      617 non-null    float64\n",
      " 33  DV      617 non-null    float64\n",
      " 34  DY      617 non-null    float64\n",
      " 35  EB      617 non-null    float64\n",
      " 36  EE      617 non-null    float64\n",
      " 37  EG      617 non-null    float64\n",
      " 38  EH      617 non-null    float64\n",
      " 39  EJ      617 non-null    object \n",
      " 40  EP      617 non-null    float64\n",
      " 41  EU      617 non-null    float64\n",
      " 42  FC      617 non-null    float64\n",
      " 43  FD      617 non-null    float64\n",
      " 44  FE      617 non-null    float64\n",
      " 45  FI      617 non-null    float64\n",
      " 46  FL      617 non-null    float64\n",
      " 47  FR      617 non-null    float64\n",
      " 48  FS      617 non-null    float64\n",
      " 49  GB      617 non-null    float64\n",
      " 50  GE      617 non-null    float64\n",
      " 51  GF      617 non-null    float64\n",
      " 52  GH      617 non-null    float64\n",
      " 53  GI      617 non-null    float64\n",
      " 54  GL      617 non-null    float64\n",
      " 55  Class   617 non-null    int64  \n",
      "dtypes: float64(53), int64(1), object(2)\n",
      "memory usage: 270.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info() # no more null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "612    0\n",
      "613    0\n",
      "614    0\n",
      "615    0\n",
      "616    0\n",
      "Name: Class, Length: 617, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>...</th>\n",
       "      <th>FI</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.209377</td>\n",
       "      <td>3109.03329</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>22.394407</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>0.699861</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>9.812214</td>\n",
       "      <td>5.555634</td>\n",
       "      <td>4126.58731</td>\n",
       "      <td>...</td>\n",
       "      <td>3.583450</td>\n",
       "      <td>7.298162</td>\n",
       "      <td>1.73855</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>11.339138</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2003.810319</td>\n",
       "      <td>22.136229</td>\n",
       "      <td>69.834944</td>\n",
       "      <td>0.120343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.145282</td>\n",
       "      <td>978.76416</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>36.968889</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.632190</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>13.517790</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5496.92824</td>\n",
       "      <td>...</td>\n",
       "      <td>10.358927</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.568932</td>\n",
       "      <td>9.292698</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>27981.562750</td>\n",
       "      <td>29.135430</td>\n",
       "      <td>32.131996</td>\n",
       "      <td>21.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470030</td>\n",
       "      <td>2635.10654</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>32.360553</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.732840</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>12.824570</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5135.78024</td>\n",
       "      <td>...</td>\n",
       "      <td>11.626917</td>\n",
       "      <td>7.709560</td>\n",
       "      <td>0.97556</td>\n",
       "      <td>1.198821</td>\n",
       "      <td>37.077772</td>\n",
       "      <td>88.609437</td>\n",
       "      <td>13676.957810</td>\n",
       "      <td>28.022851</td>\n",
       "      <td>35.192676</td>\n",
       "      <td>0.196941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.252107</td>\n",
       "      <td>3819.65177</td>\n",
       "      <td>120.201618</td>\n",
       "      <td>77.112203</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.685344</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>11.053708</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4169.67738</td>\n",
       "      <td>...</td>\n",
       "      <td>14.852022</td>\n",
       "      <td>6.122162</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>18.529584</td>\n",
       "      <td>82.416803</td>\n",
       "      <td>2094.262452</td>\n",
       "      <td>39.948656</td>\n",
       "      <td>90.493248</td>\n",
       "      <td>0.155829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.380297</td>\n",
       "      <td>3733.04844</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>14.103738</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.942255</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>102.151980</td>\n",
       "      <td>5728.73412</td>\n",
       "      <td>...</td>\n",
       "      <td>13.666727</td>\n",
       "      <td>8.153058</td>\n",
       "      <td>48.50134</td>\n",
       "      <td>0.121914</td>\n",
       "      <td>16.408728</td>\n",
       "      <td>146.109943</td>\n",
       "      <td>8524.370502</td>\n",
       "      <td>45.381316</td>\n",
       "      <td>36.262628</td>\n",
       "      <td>0.096614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AB          AF          AH         AM        AR        AX        AY  \\\n",
       "0  0.209377  3109.03329   85.200147  22.394407  8.138688  0.699861  0.025578   \n",
       "1  0.145282   978.76416   85.200147  36.968889  8.138688  3.632190  0.025578   \n",
       "2  0.470030  2635.10654   85.200147  32.360553  8.138688  6.732840  0.025578   \n",
       "3  0.252107  3819.65177  120.201618  77.112203  8.138688  3.685344  0.025578   \n",
       "4  0.380297  3733.04844   85.200147  14.103738  8.138688  3.942255  0.054810   \n",
       "\n",
       "          AZ          BC         BD   ...         FI        FL        FR  \\\n",
       "0   9.812214    5.555634  4126.58731  ...   3.583450  7.298162   1.73855   \n",
       "1  13.517790    1.229900  5496.92824  ...  10.358927  0.173229   0.49706   \n",
       "2  12.824570    1.229900  5135.78024  ...  11.626917  7.709560   0.97556   \n",
       "3  11.053708    1.229900  4169.67738  ...  14.852022  6.122162   0.49706   \n",
       "4   3.396778  102.151980  5728.73412  ...  13.666727  8.153058  48.50134   \n",
       "\n",
       "         FS         GB          GE            GF         GH         GI  \\\n",
       "0  0.094822  11.339138   72.611063   2003.810319  22.136229  69.834944   \n",
       "1  0.568932   9.292698   72.611063  27981.562750  29.135430  32.131996   \n",
       "2  1.198821  37.077772   88.609437  13676.957810  28.022851  35.192676   \n",
       "3  0.284466  18.529584   82.416803   2094.262452  39.948656  90.493248   \n",
       "4  0.121914  16.408728  146.109943   8524.370502  45.381316  36.262628   \n",
       "\n",
       "          GL  \n",
       "0   0.120343  \n",
       "1  21.978000  \n",
       "2   0.196941  \n",
       "3   0.155829  \n",
       "4   0.096614  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain = train['Class']\n",
    "print(ytrain)\n",
    "train = train.drop(['Class', 'Id'], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'A'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['EJ'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>...</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>EJ_A</th>\n",
       "      <th>EJ_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.209377</td>\n",
       "      <td>3109.03329</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>22.394407</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>0.699861</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>9.812214</td>\n",
       "      <td>5.555634</td>\n",
       "      <td>4126.58731</td>\n",
       "      <td>...</td>\n",
       "      <td>1.73855</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>11.339138</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2003.810319</td>\n",
       "      <td>22.136229</td>\n",
       "      <td>69.834944</td>\n",
       "      <td>0.120343</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.145282</td>\n",
       "      <td>978.76416</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>36.968889</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.632190</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>13.517790</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5496.92824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.568932</td>\n",
       "      <td>9.292698</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>27981.562750</td>\n",
       "      <td>29.135430</td>\n",
       "      <td>32.131996</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470030</td>\n",
       "      <td>2635.10654</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>32.360553</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.732840</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>12.824570</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5135.78024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97556</td>\n",
       "      <td>1.198821</td>\n",
       "      <td>37.077772</td>\n",
       "      <td>88.609437</td>\n",
       "      <td>13676.957810</td>\n",
       "      <td>28.022851</td>\n",
       "      <td>35.192676</td>\n",
       "      <td>0.196941</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.252107</td>\n",
       "      <td>3819.65177</td>\n",
       "      <td>120.201618</td>\n",
       "      <td>77.112203</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.685344</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>11.053708</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4169.67738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>18.529584</td>\n",
       "      <td>82.416803</td>\n",
       "      <td>2094.262452</td>\n",
       "      <td>39.948656</td>\n",
       "      <td>90.493248</td>\n",
       "      <td>0.155829</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.380297</td>\n",
       "      <td>3733.04844</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>14.103738</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.942255</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>102.151980</td>\n",
       "      <td>5728.73412</td>\n",
       "      <td>...</td>\n",
       "      <td>48.50134</td>\n",
       "      <td>0.121914</td>\n",
       "      <td>16.408728</td>\n",
       "      <td>146.109943</td>\n",
       "      <td>8524.370502</td>\n",
       "      <td>45.381316</td>\n",
       "      <td>36.262628</td>\n",
       "      <td>0.096614</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AB          AF          AH         AM        AR        AX        AY  \\\n",
       "0  0.209377  3109.03329   85.200147  22.394407  8.138688  0.699861  0.025578   \n",
       "1  0.145282   978.76416   85.200147  36.968889  8.138688  3.632190  0.025578   \n",
       "2  0.470030  2635.10654   85.200147  32.360553  8.138688  6.732840  0.025578   \n",
       "3  0.252107  3819.65177  120.201618  77.112203  8.138688  3.685344  0.025578   \n",
       "4  0.380297  3733.04844   85.200147  14.103738  8.138688  3.942255  0.054810   \n",
       "\n",
       "          AZ          BC         BD   ...        FR        FS         GB  \\\n",
       "0   9.812214    5.555634  4126.58731  ...   1.73855  0.094822  11.339138   \n",
       "1  13.517790    1.229900  5496.92824  ...   0.49706  0.568932   9.292698   \n",
       "2  12.824570    1.229900  5135.78024  ...   0.97556  1.198821  37.077772   \n",
       "3  11.053708    1.229900  4169.67738  ...   0.49706  0.284466  18.529584   \n",
       "4   3.396778  102.151980  5728.73412  ...  48.50134  0.121914  16.408728   \n",
       "\n",
       "           GE            GF         GH         GI         GL  EJ_A  EJ_B  \n",
       "0   72.611063   2003.810319  22.136229  69.834944   0.120343     0     1  \n",
       "1   72.611063  27981.562750  29.135430  32.131996  21.978000     1     0  \n",
       "2   88.609437  13676.957810  28.022851  35.192676   0.196941     0     1  \n",
       "3   82.416803   2094.262452  39.948656  90.493248   0.155829     0     1  \n",
       "4  146.109943   8524.370502  45.381316  36.262628   0.096614     0     1  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make categorical data into numerical data\n",
    "train = pd.get_dummies(train)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # referenced https://www.kaggle.com/code/dan3dewey/icr-2023-balanced-log-loss\n",
    "def competition_log_loss(y_true, y_pred):\n",
    "    # y_true: correct labels 0, 1\n",
    "    # y_pred: predicted probabilities of class=1\n",
    "    # Implements the Evaluation equation with w_0 = w_1 = 1.\n",
    "    # Calculate the number of observations for each class\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "    print(y_pred.shape)\n",
    "    # Calculate the predicted probabilities for each class\n",
    "    p_1 = np.clip(y_pred[:,1], 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "    # Calculate the average log loss for each class\n",
    "    #print(\"reached\")\n",
    "    print(p_0.shape, p_1.shape, y_true.shape)\n",
    "\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0)) / N_0\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1)) / N_1\n",
    "    # return the (not further weighted) average of the averages\n",
    "    return (log_loss_0 + log_loss_1)/2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1609: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1609: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# train test split such that same distribution of classes in train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, ytrain, test_size=0.2, random_state=42, stratify=ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Perform Variable Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n",
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59745861 0.83001421 0.95737439 0.98255972 0.98990672 0.99572479\n",
      " 0.99939251 0.99958906 0.99976719 0.99982681 0.99987752 0.99990927\n",
      " 0.9999335  0.99995185 0.99996472 0.99997391 0.99998065 0.99998623\n",
      " 0.99999039 0.99999319 0.99999498 0.99999624 0.99999733 0.99999793\n",
      " 0.99999846 0.99999881 0.99999904 0.99999924 0.99999941 0.99999954\n",
      " 0.99999965 0.99999975 0.99999983 0.99999988 0.99999991 0.99999993\n",
      " 0.99999995 0.99999997 0.99999998 0.99999999 0.99999999 0.99999999\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pca\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# determine the number of components\n",
    "pca = PCA().fit(X_train)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "print(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show() # 3 principal components is enough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(493, 3)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_train)\n",
    "train_pca = pca.transform(X_train)\n",
    "print(train_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.83\n",
      "[[405   2]\n",
      " [ 81   5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       407\n",
      "           1       0.71      0.06      0.11        86\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       493\n",
      "   macro avg       0.77      0.53      0.51       493\n",
      "weighted avg       0.81      0.83      0.77       493\n",
      "\n",
      "Accuracy of logistic regression classifier on test set: 0.85\n",
      "[[102   0]\n",
      " [ 19   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       102\n",
      "           1       1.00      0.14      0.24        22\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       124\n",
      "   macro avg       0.92      0.57      0.58       124\n",
      "weighted avg       0.87      0.85      0.80       124\n",
      "\n",
      "(124, 2)\n",
      "(124,) (124,) (124,)\n",
      "0.9086759983972672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n",
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# fit a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_pca, y_train)\n",
    "y_pred = logreg.predict(train_pca)\n",
    "print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(accuracy_score(y_train, y_pred)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "test_pca = pca.transform(X_test)\n",
    "y_pred = logreg.predict(test_pca)\n",
    "y_pred2 = logreg.predict_proba(test_pca)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(competition_log_loss(y_test, y_pred2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on train set: 1.00\n",
      "[[407   0]\n",
      " [  0  86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       407\n",
      "           1       1.00      1.00      1.00        86\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       493\n",
      "   macro avg       1.00      1.00      1.00       493\n",
      "weighted avg       1.00      1.00      1.00       493\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gary/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c3820f583d2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0my_pred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy of SVM classifier on test set: {:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \"\"\"\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[1;32m    586\u001b[0m                                  \" probability=False\")\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'c_svc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nu_svc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "# fit a svm model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(train_pca, y_train)\n",
    "y_pred = svm.predict(train_pca)\n",
    "print('Accuracy of SVM classifier on train set: {:.2f}'.format(accuracy_score(y_train, y_pred)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "y_pred = svm.predict(test_pca)\n",
    "y_pred2 = svm.predict_proba(test_pca)\n",
    "\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(competition_log_loss(y_test, y_pred2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost classifier on train set: 1.00\n",
      "[[407   0]\n",
      " [  0  86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       407\n",
      "           1       1.00      1.00      1.00        86\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       493\n",
      "   macro avg       1.00      1.00      1.00       493\n",
      "weighted avg       1.00      1.00      1.00       493\n",
      "\n",
      "Accuracy of XGBoost classifier on test set: 0.81\n",
      "[[95  7]\n",
      " [17  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       102\n",
      "           1       0.42      0.23      0.29        22\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       124\n",
      "   macro avg       0.63      0.58      0.59       124\n",
      "weighted avg       0.77      0.81      0.78       124\n",
      "\n",
      "(124, 2)\n",
      "(124,) (124,) (124,)\n",
      "1.3658423341396895\n"
     ]
    }
   ],
   "source": [
    "# fit XGBoost model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_pca, y_train)\n",
    "y_pred = xgb.predict(train_pca)\n",
    "\n",
    "print('Accuracy of XGBoost classifier on train set: {:.2f}'.format(accuracy_score(y_train, y_pred)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "y_pred = xgb.predict(test_pca)\n",
    "y_pred2 = xgb.predict_proba(test_pca)\n",
    "\n",
    "print('Accuracy of XGBoost classifier on test set: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(competition_log_loss(y_test, y_pred2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(directory, \"test.csv\"))\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>...</th>\n",
       "      <th>FI</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   AB   AF   AH   AM   AR   AX   AY   AZ   BC  ...   FI   FL  \\\n",
       "0  00eed32682bb  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1  010ebe33f668  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2  02fa521e1838  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3  040e15f562a2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "4  046e85c7cc7f  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "    FR   FS   GB   GE   GF   GH   GI   GL  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove BQ and EL since they have more 50 null values\n",
    "test = test.drop(['BQ', 'EL'], axis=1)\n",
    "\n",
    "# fill null values with mean\n",
    "null_cols = test.columns[test.isnull().any()]\n",
    "for col in null_cols:\n",
    "    test[col].fillna(test[col].mean(), inplace=True)\n",
    "\n",
    "# drop Id column\n",
    "test_id = test['Id']\n",
    "test = test.drop(['Id'], axis=1)\n",
    "\n",
    "# make categorical data into numerical data\n",
    "test = pd.get_dummies(test)\n",
    "# add a new column to test data\n",
    "\n",
    "test['EJ_B'] = 0 # delete this line when upload to kaggle\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>...</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>EJ_A</th>\n",
       "      <th>EJ_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AB   AF   AH   AM   AR   AX   AY   AZ   BC  BD   ...   FR   FS   GB   GE  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    GF   GH   GI   GL  EJ_A  EJ_B  \n",
       "0  0.0  0.0  0.0  0.0     1     0  \n",
       "1  0.0  0.0  0.0  0.0     1     0  \n",
       "2  0.0  0.0  0.0  0.0     1     0  \n",
       "3  0.0  0.0  0.0  0.0     1     0  \n",
       "4  0.0  0.0  0.0  0.0     1     0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the test data\n",
    "test_pca = pca.transform(test)\n",
    "y_prob = logreg.predict_proba(test_pca)\n",
    "\n",
    "y_prob[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17221937, 0.17221937, 0.17221937, 0.17221937, 0.17221937])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = pd.DataFrame(\n",
    "    {\n",
    "        \"Id\": test_id,\n",
    "        \"class_0\": y_prob[:,0],\n",
    "        \"class_1\": y_prob[:,1],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.827781</td>\n",
       "      <td>0.172219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.827781</td>\n",
       "      <td>0.172219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.827781</td>\n",
       "      <td>0.172219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.827781</td>\n",
       "      <td>0.172219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.827781</td>\n",
       "      <td>0.172219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   class_0   class_1\n",
       "0  00eed32682bb  0.827781  0.172219\n",
       "1  010ebe33f668  0.827781  0.172219\n",
       "2  02fa521e1838  0.827781  0.172219\n",
       "3  040e15f562a2  0.827781  0.172219\n",
       "4  046e85c7cc7f  0.827781  0.172219"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.to_csv(r\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
